{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c2bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from collections import defaultdict\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26648ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "data_dir = \"Dataset/Plant_Leaf_Dataset\"\n",
    "batch_size = 20\n",
    "num_epochs = 10\n",
    "image_size = 224\n",
    "learning_rate = 0.001\n",
    "num_workers = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomResizedCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70368232",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = datasets.ImageFolder(root=os.path.join(data_dir), transform=transform)\n",
    "class_names = full_dataset.classes\n",
    "print(\"Class Names:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2813226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_data, val_data, test_data = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Images From Test Dataset For Future Testing\n",
    "\n",
    "output_dir = \"Tests/test_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "class_counts = defaultdict(int)\n",
    "for image_path, label in test_data.dataset.samples:\n",
    "    if class_counts[label] < 5:\n",
    "\n",
    "        class_name = class_names[label]\n",
    "        class_dir = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        \n",
    "        output_path = os.path.join(class_dir, os.path.basename(image_path))\n",
    "        copyfile(image_path, output_path)\n",
    "        \n",
    "        class_counts[label] += 1\n",
    "\n",
    "    if len(class_counts) == len(class_names) and all(count >= 5 for count in class_counts.values()):\n",
    "        break\n",
    "\n",
    "print(f\"Exported 5 images per class to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c07a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedResNet(nn.Module):\n",
    "    def __init__(self, base_model, num_classes):\n",
    "        num_features = base_model.fc.in_features\n",
    "        super(ModifiedResNet, self).__init__()\n",
    "        # Extract all layers except the last (fully connected)\n",
    "        self.base = nn.Sequential(*list(base_model.children())[:-2])\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # Adaptive pooling for fixed-size output\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # Dropout to prevent overfitting\n",
    "            nn.Linear(num_features, num_classes)  # 512 is fixed for ResNet-18\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base(x)  # Feature extraction\n",
    "        x = self.pool(x)  # Adaptive pooling to (batch_size, 512, 1, 1)\n",
    "        x = torch.flatten(x, 1)  # Flatten to (batch_size, 512)\n",
    "        x = self.fc(x)  # Classification layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c9e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "num_classes = len(full_dataset.classes)  # Total classes in your dataset\n",
    "model = ModifiedResNet(base_model, num_classes)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95acc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534d91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model():\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_accuracy = validate_model(model, val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"  Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n",
    "        print(f\"  Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "        \n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a9aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_path=\"Saved-Models/leaf_disease_model.pth\"):\n",
    "    torch.save(model.state_dict(), file_path)\n",
    "    print(f\"Model saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4292dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_model()\n",
    "    save_model(model, file_path=\"Saved-Models/leaf_disease_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1069d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(base_model, num_classes, file_path=\"Saved-Models/leaf_disease_model.pth\"):\n",
    "    # Create an instance of the custom ModifiedResNet model\n",
    "    model = ModifiedResNet(base_model, num_classes)\n",
    "    \n",
    "    # Check if the model checkpoint exists\n",
    "    if os.path.exists(file_path):\n",
    "        model.load_state_dict(torch.load(file_path, map_location=device))\n",
    "        model = model.to(device)\n",
    "        print(f\"Model loaded from {file_path}\")\n",
    "    else:\n",
    "        print(f\"No model found at {file_path}. Starting with a fresh model.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e28dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = models.resnet18(weights=None)  # Initialize ResNet-18 without pretrained weights\n",
    "num_classes = len(full_dataset.classes)  # Number of classes in your dataset\n",
    "loaded_model = load_model(base_model, num_classes, file_path=\"Saved-Models/leaf_disease_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93cd6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ac167",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = test_model(loaded_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model, class_names):\n",
    "    \"\"\"Predict the class of a single image.\"\"\"\n",
    "    # Transform the image to match the model's input\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),  # Resize to the model's input size\n",
    "        transforms.ToTensor(),         # Convert to Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "    ])\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure it's in RGB format\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    \n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        _, predicted_class = torch.max(output, 1)  # Get the class with the highest score\n",
    "    \n",
    "    return class_names[predicted_class.item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd4f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_directory(directory_path, model, class_names):\n",
    "    \"\"\"Iterate through subdirectories and predict the class for each image.\"\"\"\n",
    "    for subdir in os.listdir(directory_path):\n",
    "        subdir_path = os.path.join(directory_path, subdir)\n",
    "        \n",
    "        # Skip if not a directory\n",
    "        if not os.path.isdir(subdir_path):\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing directory: {subdir}\")\n",
    "        \n",
    "        # Iterate through the first 5 images in the directory\n",
    "        for idx, image_name in enumerate(sorted(os.listdir(subdir_path))[:5]):\n",
    "            image_path = os.path.join(subdir_path, image_name)\n",
    "            \n",
    "            # Skip non-image files\n",
    "            if not image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                continue\n",
    "            \n",
    "            # Predict the class of the image\n",
    "            predicted_class = predict_image(image_path, model, class_names)\n",
    "            print(f\"Image {idx + 1}: {image_name} -> Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5346b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test directory and call the function\n",
    "test_directory = \"Tests/test_images\"\n",
    "predict_directory(test_directory, loaded_model, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = full_dataset.classes\n",
    "\n",
    "image_path = \"Tests/test_images/Tomato__Tomato_Yellow_Leaf_Curl_Virus/image (1).jpg\"\n",
    "predict_image(image_path, loaded_model, class_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
